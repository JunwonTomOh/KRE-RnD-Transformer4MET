import abc
from typing import Any, Sequence
import warnings
import logging
from textwrap import indent
import torch.nn as nn
from torch import Tensor
from tensordict import TensorDictBase, LazyStackedTensorDict
from tensordict.nn import TensorDictModule, TensorDictSequential
from tensordict._tensordict import unravel_key_list
from tensordict.nn.common import dispatch, set_skip_existing


class Transform(nn.Module, metaclass=abc.ABCMeta):

    @abc.abstractmethod
    def forward(self, *args, **kwargs) -> Tensor | Sequence[Tensor]:
        ...

    @abc.abstractmethod
    def inverse(self, *args, **kwargs) -> Tensor | Sequence[Tensor]:
        ...


class TensorDictTransform(TensorDictModule):
    """adapted from https://github.com/pytorch/tensordict/blob/v0.3.1/tensordict/nn/common.py#L1139-L1221
    """
    module: Transform

    def _call_module_inverse(
        self, tensors: Sequence[Tensor], **kwargs: Any
    ) -> Tensor | Sequence[Tensor]:
        out = self.module.inverse(*tensors, **kwargs)
        return out


    @dispatch(auto_batch_size=False)
    @set_skip_existing(None)
    def inverse(
        self,
        tensordict: TensorDictBase,
        *args,
        tensordict_out: TensorDictBase | None = None,
        **kwargs: Any,
    ) -> TensorDictBase:

        try:
            if len(args):
                tensordict_out = args[0]
                args = args[1:]
                # we will get rid of tensordict_out as a regular arg, because it
                # blocks us when using vmap
                # with stateful but functional modules: the functional module checks if
                # it still contains parameters. If so it considers that only a "params" kwarg
                # is indicative of what the params are, when we could potentially make a
                # special rule for TensorDictModule that states that the second arg is
                # likely to be the module params.
                warnings.warn(
                    "tensordict_out will be deprecated soon.",
                    category=DeprecationWarning,
                )
            if len(args):
                raise ValueError(
                    "Got a non-empty list of extra agruments, when none was expected."
                )
            if self._kwargs is not None:
                kwargs.update(
                    {
                        kwarg: tensordict.get(out_key, None)
                        for kwarg, out_key in zip(self._kwargs, self.out_keys)
                    }
                )
                tensors = ()
            else:
                tensors = tuple(tensordict.get(out_key, None) for out_key in self.out_keys)
            try:
                tensors = self._call_module_inverse(tensors, **kwargs)
            except Exception as err:
                if any(tensor is None for tensor in tensors) and "None" in str(err):
                    none_set = {
                        key
                        for key, tensor in zip(self.out_keys, tensors)
                        if tensor is None
                    }
                    raise KeyError(
                        "Some tensors that are necessary for the module call may "
                        "not have not been found in the input tensordict: "
                        f"the following inputs are None: {none_set}."
                    ) from err
                else:
                    raise err
            if isinstance(tensors, (dict, TensorDictBase)):
                if isinstance(tensors, dict):
                    keys = unravel_key_list(list(tensors.keys()))
                    values = tensors.values()
                    tensors = dict(zip(keys, values))
                tensors = tuple(tensors.get(key, None) for key in self.in_keys)
            if not isinstance(tensors, tuple):
                tensors = (tensors,)
            tensordict_out = self._write_to_tensordict(
                    tensordict, tensors, tensordict_out # type: ignore
            )
            return tensordict_out
        except Exception as err:
            module = self.module
            if not isinstance(module, nn.Module):
                try:
                    import inspect

                    module = inspect.getsource(module)
                except OSError:
                    # then we can't print the source code
                    pass
            module = indent(str(module), 4 * " ")
            in_keys = indent(f"in_keys={self.in_keys}", 4 * " ")
            out_keys = indent(f"out_keys={self.out_keys}", 4 * " ")
            raise err from RuntimeError(
                f"TensorDictModule failed with operation\n{module}\n{in_keys}\n{out_keys}."
            )


class TensorDictTransformSequential(TensorDictSequential):

    def _run_module_inverse(
        self,
        module: TensorDictModule,
        tensordict: TensorDictBase,
        **kwargs: Any,
    ) -> Any:
        if not self.partial_tolerant or all(
            key in tensordict.keys(include_nested=True) for key in module.out_keys
        ):
            tensordict = module.inverse(tensordict, **kwargs)
        elif self.partial_tolerant and isinstance(tensordict, LazyStackedTensorDict):
            for sub_td in tensordict.tensordicts:
                if all(
                    key in sub_td.keys(include_nested=True) for key in module.out_keys
                ):
                    module.inverse(sub_td, **kwargs)
        return tensordict

    @dispatch(auto_batch_size=False)
    @set_skip_existing(None)
    def inverse(
        self,
        tensordict: TensorDictBase,
        tensordict_out: TensorDictBase | None = None,
        **kwargs: Any,
    ) -> TensorDictBase:
        if not len(kwargs):
            for module in reversed(self.module):
                tensordict = self._run_module_inverse(module, tensordict, **kwargs)
        else:
            raise RuntimeError(
                f"TensorDictSequential does not support keyword arguments other than 'tensordict_out' or in_keys: {self.in_keys}. Got {kwargs.keys()} instead."
            )
        if tensordict_out is not None:
            tensordict_out.update(tensordict, inplace=True)
            return tensordict_out
        return tensordict
